) |>
add_trace(
x =  df$x[1],
y =  df$y[1],
type = 'scatter',
mode = 'markers',
marker = list(color = "purple"),
name = 'Start'
) |>
add_trace(
x =  df$x[n],
y =  df$y[n],
type = 'scatter',
mode = 'markers',
name = 'Min',
marker = list(color = "red")
) |> add_trace(
x =  edf$x,
y =  edf$y,
type = 'scatter',
mode = 'markers',
name = 'Вычисления функции',
marker = list(color = "red")
)
}
library(DescTools)
gradient_path <- function(f_g, path)
{
df <- path
rescale <- function(x,first,last){(last-first)/(max(x)-min(x))*(x-min(x))+first}
lower <- apply(df, 2, min)
upper <- apply(df, 2, max)
x <- seq(lower[1], upper[1], length.out = 15)
y <- seq(lower[2], upper[2], length.out = 15)
n <- nrow(df)
g_grid <- expand.grid(x = x, y = y)
g_val <- apply(g_grid, 1,\(par) {gr <- f_g(par); CartToPol(gr[1],gr[2]) |> unlist()}) |> t()
g_grid$theta <- g_val[,2]
g_grid$r <- g_val[,1] |> log() |> rescale(0, ((upper - lower) / 15) |> min() )
fig <- ggplot(g_grid, aes(x, y)) +
geom_point() +
geom_spoke(aes(angle = theta, radius = r))
ggplotly(fig) |>
add_trace(
x =  df$x,
y =  df$y,
type = 'scatter',
mode = 'lines+markers',
name = 'оптимизация'
) |>
add_trace(
x =  df$x[1],
y =  df$y[1],
type = 'scatter',
mode = 'markers',
marker = list(color = "purple"),
name = 'начало'
) |>
add_trace(
x =  df$x[n],
y =  df$y[n],
type = 'scatter',
mode = 'markers',
name = 'Min',
marker = list(color = "red")
)
}
library(digest)
library(extraDistr)
require(dfoptim)
base_seed <- digest2int('Дроздовская Полина')
listN <- function(...){ # используется для создания списка из аргументов, переданных ей.
anonList <- list(...)
names(anonList) <- as.character(substitute(list(...)))[-1]
anonList
}
frac <- \(a,b)a/b
task1_gen <- function()
{
set.seed(seed) # - устанавливает начальное значение для генератора случайных чисел
la <- rdunif(1, 7, 12) |> as.integer()
ca <- rdunif(1, 7, 12) |> as.integer()
a <- rdunif(1, 1, 3) |> as.integer()
b <- rdunif(1, 1, 5) |> as.integer()
o <- rdunif(1, 1, 4) |> as.integer()
expr <-
substitute(la * frac(1L, 1L + exp(-x)) + ca * cos(o*x) + a * x ^ 2L - b * x)
f <- \(x) eval(expr) # - принимает x и вычисляет значение выражения expr
listN(f, expr)
}
task1 <- task1_gen()
task1$expr
x <- seq(-2,2, by = 0.1)
y <- task1$f(x)
op <- optimise(task1$f, c(-5, 5))
data <- data.frame(x, y)
fig <- plot_ly(data, x = ~x, y = ~y, type = 'scatter', mode = 'lines', name = "Function") |>
add_markers(x = op$minimum, y = task1$f(op$minimum))
fig
task2_gen <- function()
{
set.seed(base_seed+2)
a <- rdunif(1, 5, 10) |> as.integer()
c <- rdunif(1, 5, 10) |> as.integer()
b <- (sqrt(a*c) - 1) |> ceiling() |> as.integer()
ae1 <- rdunif(1, 5, 10) |> as.integer()
ae2 <- rdunif(1, 5, 10) |> as.integer()
ae3 <- rdunif(1, 5, 10) |> as.integer()
x01 <- rdunif(1, -3, 3) |> as.integer()
x02 <- rdunif(1, -3, 3) |> as.integer()
x03 <- rdunif(1, -3, 3) |> as.integer()
y01 <- rdunif(1, -3, 3) |> as.integer()
y02 <- rdunif(1, -3, 3) |> as.integer()
y03 <- rdunif(1, -3, 3) |> as.integer()
sx1 <- rdunif(1, 1, 5) |> as.integer()
sx2 <- rdunif(1, 1, 5) |> as.integer()
sx3 <- rdunif(1, 1, 5) |> as.integer()
sy1 <- rdunif(1, 1, 5) |> as.integer()
sy2 <- rdunif(1, 1, 5) |> as.integer()
sy3 <- rdunif(1, 1, 5) |> as.integer()
expr <- substitute(
a * x ^ 2L + 2L * b * x * y + c * y ^ 2L + ae1 * exp(-(frac((x - x01) ^ 2L,sx1) + frac((y - y01) ^ 2L , sy1))) + ae2 * exp(-(frac((x - x02) ^ 2L,sx2) + frac((y - sy2) ^ 2L , sy2))) + ae3 * exp(-(frac((x - x03) ^ 2L , sx3) + frac((y - y03) ^ 2L , sy3))))
f <- \(par) eval(expr, list(x = par[1], y = par[2]))
listN(f, expr)
}
task2 <- task2_gen()
task2$expr
task2_gen <- function()
{
set.seed(base_seed+2)
a <- rdunif(1, 5, 10) |> as.integer()
c <- rdunif(1, 5, 10) |> as.integer()
b <- (sqrt(a*c) - 1) |> ceiling() |> as.integer()
ae1 <- rdunif(1, 5, 10) |> as.integer()
ae2 <- rdunif(1, 5, 10) |> as.integer()
ae3 <- rdunif(1, 5, 10) |> as.integer()
x01 <- rdunif(1, -3, 3) |> as.integer()
x02 <- rdunif(1, -3, 3) |> as.integer()
x03 <- rdunif(1, -3, 3) |> as.integer()
y01 <- rdunif(1, -3, 3) |> as.integer()
y02 <- rdunif(1, -3, 3) |> as.integer()
y03 <- rdunif(1, -3, 3) |> as.integer()
sx1 <- rdunif(1, 1, 5) |> as.integer()
sx2 <- rdunif(1, 1, 5) |> as.integer()
sx3 <- rdunif(1, 1, 5) |> as.integer()
sy1 <- rdunif(1, 1, 5) |> as.integer()
sy2 <- rdunif(1, 1, 5) |> as.integer()
sy3 <- rdunif(1, 1, 5) |> as.integer()
expr <- substitute(
a * x ^ 2L + 2L * b * x * y + c * y ^ 2L + ae1 * exp(-(frac((x - x01) ^ 2L,sx1) + frac((y - y01) ^ 2L , sy1))) + ae2 * exp(-(frac((x - x02) ^ 2L,sx2) + frac((y - sy2) ^ 2L , sy2))) + ae3 * exp(-(frac((x - x03) ^ 2L , sx3) + frac((y - y03) ^ 2L , sy3))))
f <- \(par) eval(expr, list(x = par[1], y = par[2]))
listN(f, expr)
}
task2 <- task2_gen()
task2$expr
library(Deriv)
f = function(par){
x <- par[1]
y <- par[2]
8 * x^2 + 14 * x * y + 7 * y^2 + 6 * exp(-(frac((x - 3)^2, 3) + frac((y)^2, 2))) + 9 * exp(-(frac((x - 3)^2, 1) + frac((y - 4)^2, 4))) + 6 * exp(-(frac((x - 1)^2, 4) + frac((y - 3)^2, 4)))
}
df_dx <- Deriv(f, "x")
df_dy <- Deriv(f, "y")
df_dx
task2 <- list(
f = function(par){
x <- par[1]
y <- par[2]
8 * x^2 + 14 * x * y + 7 * y^2 + 6 * exp(-(frac((x - 3)^2, 3) + frac((y)^2, 2))) + 9 * exp(-(frac((x - 3)^2, 1) + frac((y - 4)^2, 4))) + 6 * exp(-(frac((x - 1)^2, 4) + frac((y - 3)^2, 4)))
},
gradF = function(par){
x <- par[1]
y <- par[2]
dx <- 20 * x + 18 * y - 8 * exp(-((((x-1)^2)/5) + ((y-1)^2)/3)) * (2 * (x - 1) / 5) - 10 * exp(-((((x-3)^2)/1) + ((y-5)^2)/5)) * (2 * (x - 3) / 1) - 10 * exp(-((((x-3)^2)/1) + ((y-2)^2)/5)) * (2 * (x - 3) / 1)
dy <- 18 * x + 20 * y - 8 * exp(-((((x-1)^2)/5) + ((y-1)^2)/3)) * (2 * (y - 1) / 3) - 10 * exp(-((((x-3)^2)/1) + ((y-5)^2)/5)) * (2 * (y - 5) / 5) - 10 * exp(-((((x-3)^2)/1) + ((y-2)^2)/5)) * (2 * (y - 2) / 5)
c(dx, dy)
},
hess_f = function(par){
x <- par[1]
y <- par[2]
ddx <- 20 - 8 * exp(-((x-1)^2/5 + (y-1)^2/3)) * (2/5) + 8 * exp(-((x-1)^2/5 + (y-1)^2/3)) * (2*(x-1)^2/25) - 20 * exp(-((x-3)^2 + (y-5)^2/5)) * (2*(x-3)^2) - 20 * exp(-((x-3)^2 + (y-2)^2/5)) * (2*(x-3)^2)
ddy <- 20 - 8 * exp(-((x-1)^2/5 + (y-1)^2/3)) * (2/3) + 8 * exp(-((x-1)^2/5 + (y-1)^2/3)) * (2*(y-1)^2/9) - 10 * exp(-((x-3)^2 + (y-5)^2/5)) * (2*(y-5)^2/25) - 10 * exp(-((x-3)^2 + (y-2)^2/5)) * (2*(y-2)^2/25)
dxdy <- 18 - 8 * exp(-((x-1)^2/5 + (y-1)^2/3)) * (2*(x-1)*(y-1)/15) - 20 * exp(-((x-3)^2 + (y-5)^2/5)) * (2*(x-3)*(y-5)/5) - 20 * exp(-((x-3)^2 + (y-2)^2/5)) * (2*(x-3)*(y-2)/5)
rbind(c(ddx, dxdy), c(dxdy, ddy))
}
)
start <- c(-5,5)
library(nloptr)
Res <- nloptr(
x0 = start,
eval_f = task2$f,
opts = list(algorithm = 'NLOPT_LN_NELDERMEAD', xtol_rel = 1.0e-8)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
opts = list(algorithm = 'NLOPT_LN_NELDERMEAD', xtol_rel = 1.0e-8)
)
animated_path(res)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
df <- data.frame()
row <- data.frame(
method = "Nelder-Mead",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
Res <- nloptr(
x0 = start,
eval_f = task2$f,
opts = list(algorithm = 'NLOPT_LN_PRAXIS', xtol_rel = 1.0e-8)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
opts = list(algorithm = 'NLOPT_LN_PRAXIS', xtol_rel = 1.0e-8)
)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
Res <- nloptr(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
opts = list(algorithm = 'NLOPT_LD_LBFGS', xtol_rel = 1.0e-8)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
opts = list(algorithm = 'NLOPT_LD_LBFGS', xtol_rel = 1.0e-8) # BFGS - Метод ограниченной памяти Бройдена-Флетчера-Голдфарба-Шанно (Broyden-Fletcher-Goldfarb-Shanno). Это алгоритм оптимизации второго порядка, который использует информацию о градиенте и Гессиане целевой ф-ции для поиска оптимального решения.
)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
row <- data.frame(
method = "BFGS",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
library(optimx)
Res <- optimx(
par = start,
fn = task2$f,
gr = task2$gradF,
hess = task2$hess_f,
method = 'CG'
)
#library(optimx)
#Res <- optimx(
#  par = start,
#  fn = task2$f,
#  gr = task2$gradF,
#  hess = task2$hess_f,
#  method = 'CG'
#)
#Res
task3_linear <- function()
{
set.seed(base_seed+3)
a <- rdunif(1, 2, 10) |> as.integer()
b <- rdunif(1,-10, 10) |> as.integer()
c <- rdunif(1,-10, 10) |> as.integer()
f <- rdunif(1, -10, 10) |> as.integer()
f1 <- round(f/2L) |> as.integer()
first <- substitute(a * x + b * y <= f)
second <- substitute(frac(x, a) + c * y >= -f1)
list(first = first, second = second)
}
task3_quadratic <- function()
{
set.seed(base_seed+3)
a <- rdunif(1, 6, 15) |> as.integer()
c <- rdunif(1, 2, 10) |> as.integer()
k <- rdunif(1, 1, 5) |> as.integer()
b <- (sqrt(a * c) - 1) |> ceiling() |> as.integer()
first <- substitute(frac(x ^ 2L, a) + frac(y ^ 2L, c) - frac(x * y, b) <= 6L)
second <- substitute(frac(x ^ 2L, c) + frac(y ^ 2L, a * k) + frac(x * y, b) <= 3L)
listN(first, second)
}
task3_gen <- function()
if(sample(c(TRUE,FALSE),1)) task3_quadratic() else task3_linear()
task3 <- task3_gen()
task3
constr_ineq <- function(par){
x <- par[1]
y <- par[2]
c((x^2 / 9) + (y^2 / 4) - (x * y / 5) - 6, (x^2 / 4) + (y^2 / (9 * 4)) + (x * y / 5) - 3)
}
Res <- nloptr(
x0 = start, # Начальное приближение для переменных решения. start — это вектор начальных значений.
eval_f = task2$f, # Целевая функция, которую нужно минимизировать.
eval_g_ineq = constr_ineq, # Неравенства, которые должны быть выполнены в процессе оптимизации. constr_ineq — это функция, которая возвращает вектор значений ограничений.
opts = list( # Список опций для настройки алгоритма оптимизации. В данном случае:
algorithm = 'NLOPT_LN_COBYLA', # Используется алгоритм COBYLA (Constrained Optimization BY Linear Approximations).
xtol_rel = 1.0e-8 # Относительная допустимая ошибка в значениях переменных, которая является критерием остановки.
)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
eval_g_ineq = constr_ineq,
opts = list(
algorithm = 'NLOPT_LN_COBYLA',
xtol_rel = 1.0e-8
)
)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
row <- data.frame(
method = "COBYLA",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
row <- data.frame(
method = "PRAXIS",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
df <- data.frame( # - создает таблицу df для хранения результатов анализа.
method = c(),
num_features = c(),
iter = c(),
MSE_metric = c()
)
df <- data.frame()
row <- data.frame(
method = "Nelder-Mead",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
row <- data.frame(
method = "PRAXIS",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
row <- data.frame(
method = "BFGS",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
row <- data.frame(
method = "COBYLA",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
# constr_ineq_jac - функция, которая возвращает якобиан неравенств. Якобиан — это матрица первых производных функций ограничений. В данном примере функция принимает вектор par из двух элементов (x, y) и возвращает матрицу 2x2, где каждая строка представляет собой градиент одного из ограничений.
constr_ineq_jac <- function(par){
x <- par[1]
y <- par[2]
rbind(c(2*x/9, y/2 - x/5),
c(x/2 + y/5, y/36 + x/5))
}
Res <- nloptr(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF, # Градиент целевой функции. Функция task2$gradF возвращает вектор первых производных целевой функции.
eval_g_ineq = constr_ineq, # Неравенства, которые должны быть выполнены в процессе оптимизации. constr_ineq — это функция, которая возвращает вектор значений ограничений.
eval_jac_g_ineq = constr_ineq_jac, # Якобиан неравенств. constr_ineq_jac — это функция, которая возвращает матрицу первых производных функций ограничений.
opts = list(
algorithm = 'NLOPT_LD_MMA',
xtol_rel = 1.0e-8
)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
eval_g_ineq = constr_ineq,
eval_jac_g_ineq = constr_ineq_jac,
opts = list(
algorithm = 'NLOPT_LD_MMA',
xtol_rel = 1.0e-8
)
)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
Res <- nloptr(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
eval_g_ineq = constr_ineq, # Неравенства, которые должны быть выполнены в процессе оптимизации. constr_ineq — это функция, которая возвращает вектор значений ограничений.
eval_jac_g_ineq = constr_ineq_jac, # Якобиан неравенств. constr_ineq_jac — это функция, которая возвращает матрицу первых производных функций ограничений.
opts = list(
algorithm = 'NLOPT_LD_CCSAQ', # - оптимизация с ограничениями с использованием последовательных квадратичных аппроксимаций
xtol_rel = 1.0e-8
)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
eval_g_ineq = constr_ineq,
eval_jac_g_ineq = constr_ineq_jac,
opts = list(
algorithm = 'NLOPT_LD_CCSAQ',
xtol_rel = 1.0e-8
)
)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
row <- data.frame(
method = "CCSA",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
Res <- nloptr(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
eval_g_ineq = constr_ineq, # Неравенства, которые должны быть выполнены в процессе оптимизации.
eval_jac_g_ineq = constr_ineq_jac, # Якобиан неравенств.
opts = list(
algorithm = 'NLOPT_LD_SLSQP',
xtol_rel = 1.0e-8
)
)
Res
res <- nloptr_trace(
x0 = start,
eval_f = task2$f,
eval_grad_f = task2$gradF,
eval_g_ineq = constr_ineq,
eval_jac_g_ineq = constr_ineq_jac,
opts = list(
algorithm = 'NLOPT_LD_SLSQP',
xtol_rel = 1.0e-8
)
)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
animated_path(res)
static_path(res)
gradient_path(task2$gradF, res$path)
row <- data.frame(
method = "SSLQP",
num_features = c(2),
iter = c(Res$iterations),
value = Res$objective
)
df <- rbind(df, row)
df
task4_gen <- function()
{
set.seed(base_seed+4)
x_min <- rdunif(1, -10, 10) |> as.integer()
x_max <- rdunif(1,x_min + 2, x_min + 1 + 10) |> as.integer()
y_min <- rdunif(1, -10, 10) |> as.integer()
y_max <- rdunif(1, y_min + 1, y_min + 1 + 10) |> as.integer()
listN(x_min,x_max,y_min,y_max)
}
task4 <- task4_gen()
task4
start <- c(4, -6)
lo <- c(task4$x_min |> as.numeric(), task4$y_min |> as.numeric())
up <- c(task4$x_max |> as.numeric(), task4$y_max |> as.numeric())
Res <- nloptr(
x0 = start,
eval_f = task2$f,
lb = lo,
ub = up,
opts = list(algorithm = 'NLOPT_LN_NELDERMEAD', xtol_rel = 1.0e-8)
)
start <- c(-5, -9)
lo <- c(task4$x_min |> as.numeric(), task4$y_min |> as.numeric())
up <- c(task4$x_max |> as.numeric(), task4$y_max |> as.numeric())
Res <- nloptr(
x0 = start,
eval_f = task2$f,
lb = lo,
ub = up,
opts = list(algorithm = 'NLOPT_LN_NELDERMEAD', xtol_rel = 1.0e-8)
)
Res
